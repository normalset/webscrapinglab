{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4db4d5f3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center> Laboratorio di WebScraping </h1>\n",
    "<h1><center> Anno Accademico 2023-2024 </h1>\n",
    "<h1><center>  Docente: Laura Ricci </h1>\n",
    "<h1><center>  Lezione 17 </h1>\n",
    "<h1><center>  Selenium: Implicit e Explicit Wait</h1>\n",
    "<h1><center>  Crawling Sites</h1>  \n",
    "<h1><center>  Bitcoin DataSet</h1> \n",
    "<h1><center> 10 Aprile 2024 </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e09d8c6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Perchè c'è bisogno di Wait in Selenium?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77847181",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"Figures/PageWait.jpg\" style=\"width:600px;height:150px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad5aede",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* uso di **AjaX** e **JAVAScript**\n",
    "* gli elementi con cui vogliamo interagire sono caricati in momenti diversi\n",
    "* se l'elemento non è ancora stato caricato, può essere sollevata **NoSuchElementException**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cd431d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Selenium Wait Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094e74fb",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* vi sono situazioni in cui è necessario **attendere** prima di interagire con gli elementi della pagina\n",
    "\n",
    "* le operazioni di **wait** consentono di **attendere** che un elemento sia **caricato**, prime di eseguire una qualsiasi azione su tale elemento\n",
    "\n",
    "* **Selenium** offre il package **Wait** che include tre tipi di **wait**\n",
    "    * **Explicit Waits**\n",
    "    * **Implicit Waits**\n",
    "    * **Fluent Waits**\n",
    "\n",
    "* possibile utilizzare anche la funzione **sleep** di **Python**\n",
    "    * aspetta per un intervallo di tempo predeterminato\n",
    "    * non consigliato perchè imposta un tempo assoluto, non collegato al caricamento degli elementi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de61201",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Selenium Implicit Wait"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a801024",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* impostano un **tempo di attesa globale**\n",
    "* quando si ricerca un elemento nel **DOM**, e l'lemento non esiste,  il WebDriver interroga la pagina ripetutamente per un certo periodo di tempo\n",
    "* lo stesso tempo di attesa per **ogni elemento**\n",
    "    * una sorta di **catch all**, un tempo valido per tutti gli elementi    \n",
    "* differenza con **time.sleep()**\n",
    "    * non appena l'elemento è caricato, prosegue con l'esecuzione, invece la **sleep** attende comunque l'intervallo di tempo prestabilito\n",
    "    * se passa l'intervallo di tempo stabilito, viene sollevata una **NoSuchElementException**\n",
    "* applicato a tutti i successivi comandi del **WebDriver** e valido per l'intera sessione, **per default vale 0**\n",
    "* la sintassi è la seguente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caea588d-0b7a-4dbf-bf99-5aca47b33d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(10) # seconds\n",
    "driver.get(\"http://somedomain/url_that_delays_loading\")\n",
    "myDynamicElement = driver.find_element_by_id(\"myDynamicElement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ffa10e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Selenium Explicit Wait: Expected Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7f2e35",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* applicabile a **elementi specifici**, con **condizioni specifiche**, ad esempio il fatto che uno specifico elemento diventi visibile o cliccabile\n",
    "\n",
    "  -> Richiede la libreria ```from selenium.webdriver.support import expected_conditions as EC ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c996be04-1ec8-4204-886b-d274d97c9e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "driver = webdriver.Firefox()\n",
    "driver.get(\"http://somedomain/url_that_delays_loading\")\n",
    "try:\n",
    "    element = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, \"myDynamicElement\")))\n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e1af54-099d-4e2a-b752-2e6f234cb750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27cc88e8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Selenium Explicit Wait: Expected Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7e6588",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* **element_to_be_clickable(locator)**: aspetta che l'elemento sia visibile e abilitato a ricevere un click\n",
    "\n",
    "* **visibility_of_element_located(locator)**: aspetta che l'elemento sia presente nel **DOM** e visibile\n",
    "\n",
    "* **presence_of_element_located(locator)**: aspetta che l'elemento sia visibile nel **DOM**\n",
    "\n",
    "* **title_contains(title)**: aspetta che il titolo della pagina contenga un testo specifico\n",
    "\n",
    "* **text_to_be_present_in_element(locator, text)**: Aspetta che uno specifico testo sia presente in nuno specifico elemento\n",
    "\n",
    "* **invisibility_of_element_located(locator)**: aseptta che un elemento diventi invisisbile\n",
    "\n",
    "* .....\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce5e00b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Selenium Fluent Wait"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8880cd",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* un tipo di **Explicit Wait** che fornisce ulteriori parametri di configurazione\n",
    "* particolarmente utile quando \n",
    "    * si vuole controllare la condizione a intervalli regolari\n",
    "    * si vogliono ignorare certi tipi di eccezioni durante il periodo di wait\n",
    "    \n",
    "    \n",
    "<code>\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "driver = webdriver.Firefox()\n",
    "driver.get(\"http://somedomain/url_that_delays_loading\")\n",
    "try:\n",
    "        element = WebDriverWait(driver, timeout=30, poll_frequency=5, ignored_exceptions= [NoSuchElementException]).\n",
    "                                         until(EC.presence_of_element_located((By.ID, \"myDynamicElement\")))\n",
    "finally:\n",
    "    driver.quit()\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e4f5ad",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scraping IATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2e7132",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* **http://www.iata.org/publications/Pages/code-search.aspx**\n",
    "* un motore di ricerca per la ricerca di\n",
    "    * **compagnie aeree**, dato il codice di 2 lettere della compagnia restituisce il nome e viceversa\n",
    "    * **aereoporti**, dato il codice di 3 lettere dell'aereoporto, ne restituisce il nome e viceversa\n",
    "* elementi importanti per la risoluzione dell'esercizio\n",
    "    * il sito manda un **pop up** \n",
    "        **We use cookies to give you the best experience on our website. We also use cookies for advertising purposes.\n",
    "        Please see our privacy policy and cookies policy for complete information.**\n",
    "        ** occorre cliccre il bottone **Ok, I got it**\n",
    "    * inviare i dati in una form di ricerca\n",
    "    * appare una tabella di dati come risposta\n",
    "    * vogliamo inserire i dati ricevuti in un DataFrame **PANDAS**\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b0a20f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scraping IATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286e716d",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"Figures/IATA.jpg\" style=\"width:700px;height:500px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca89824d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scraping IATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8da6a1",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"Figures/Ryanair.jpg\" style=\"width:700px;height:500px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9527e892",
   "metadata": {},
   "source": [
    "## Scraping IATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828ad2c4",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"Figures/GotIt.jpg\" style=\"width:700px;height:500px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e695a16f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scraping IATA: Implicit wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27d42377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "url = 'https://www.iata.org/en/publications/directories/code-search/'\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990dd8ff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scraping IATA: Implicit wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1874ad6",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_results(airline_name):\n",
    "    driver.get(url)\n",
    "    time.sleep(10)\n",
    "    element = driver.find_element(By.CSS_SELECTOR,\"body > div.gdpr-banner > div > div.gdpr-button-wrapper > button\")\n",
    "    print(element)\n",
    "    element.click()  \n",
    "    driver.find_element(By.NAME,\"airline.search\").send_keys(airline_name)\n",
    "    button=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div/div/div[2]/main/div[3]/div[1]/div/form/div[2]/div[1]/div[2]/button\")  \n",
    "    button.click()  \n",
    "    print(\"cliccato!\")\n",
    "    print(\"*****************\")\n",
    "   \n",
    "    button.click() \n",
    "    element = (By.CLASS_NAME,\"datatable\")\n",
    "    table=driver.find_element(By.CLASS_NAME,\"datatable\")\n",
    "    table_html = table.get_attribute('outerHTML')\n",
    "    df = pandas.read_html(str(table_html))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79d1279",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scraping IATA: Implicit wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65ce9cd",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df = get_results('Ryanair')\n",
    "print(\"****\")\n",
    "print(df)\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc1cd4c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scraping IATA: Explicit wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315fa510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "url = 'https://www.iata.org/en/publications/directories/code-search/'\n",
    "driver = webdriver.Chrome()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88f118a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scraping IATA: Explicit wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e747528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(airline_name):\n",
    "    driver.get(url)   \n",
    "    try:\n",
    "        element = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR,\"body > div.gdpr-banner > div > div.gdpr-button-wrapper > button\"))\n",
    "    )\n",
    "    except:\n",
    "        driver.quit()\n",
    "    element.click()  \n",
    "    driver.find_element(By.NAME,\"airline.search\").send_keys(airline_name)\n",
    "    button=driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div/div/div[2]/main/div[3]/div[1]/div/form/div[2]/div[1]/div[2]/button\")  \n",
    "    button.click()  \n",
    "    print(\"cliccato!\")\n",
    "    print(\"*****************\")\n",
    "   \n",
    "    button.click() \n",
    "    table = WebDriverWait(driver, 10).until(\n",
    "             EC.presence_of_element_located((By.CLASS_NAME,\"datatable\")))\n",
    "    table_html = table.get_attribute('outerHTML')\n",
    "    df = pandas.read_html(str(table_html))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39866ab7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scraping IATA: Explicit wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf6231a",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df = get_results('Ryanair')\n",
    "print(\"****\")\n",
    "print(df)\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb00796",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Web Scraping o Web Crawling?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdc6cae",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* i termini **Web Scraping** e **Web Crawling** sono spesso utilizzati in modo intercambiabile e non preciso\n",
    "\n",
    "* in effetti, le due tecniche condividono alcune caratteristiche, ma sono diverse\n",
    "\n",
    "* **Web Scraping**\n",
    "    * estrazione di dati da una pagina web o anche da più pagine di un sito web\n",
    "    * generalmente si individua a priori un insieme di pagine da cui si vuole estrarre informazione, per poi analizzarla\n",
    "    * esempio\n",
    "        * una azienda vuole fare ricerche di mercato per lanciare un nuovo prodotto, ad esempio un nuovo laptop\n",
    "        * estrae da **Amazon** la lista dei laptop sul mercato con il relativo prezzo, per capire come posizionarsi\n",
    "          sul mercato\n",
    "        * non è limitato ad una singola pagina, ma comunque viene effettuato su un insieme di pagine predeterminato\n",
    "        \n",
    "* **Web crawling**\n",
    "    * utilizza **bots** o **spiders** per leggere tutto il contenuto di un sito web e/o di più siti web\n",
    "    * in genere utilizzato per indicizzare il contenuto di un sito web, dai search engines (**Google**, **Bing**,...)\n",
    "        * iniziare da una **parola chiave** inserita in un motore di ricerca\n",
    "        * crawling di tutte le pagine restituite per quella parola chiave\n",
    "        * collezione di immagini, liste, tabelle da tutte le pagine\n",
    "        * navigare tra domini diversi, sul web"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f52c11",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Web Crawling: metodologie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73503be8",
   "metadata": {},
   "source": [
    "* preferibile usare un database per salvare i dati: molto spesso la varietà e la quantità dei dati richiedono l'uso di un database vero e proprio, piuttosto che un file .**csv**, oppure **JSON**\n",
    "* strutturare il programma in modo da separare la parte di **crawling** dalla parte di **scraping**\n",
    "    * **crawling**\n",
    "        * visita del siti, estrazione di links, inserimento dei link in una coda per essre considerati sequenzialmente\n",
    "    * **scraping**\n",
    "        * estrarre l'informazione di interesse dalle pagine reperite\n",
    "* stabilire una condizione di **terminazione** del processo di **crawling**\n",
    "    * durante il processo di crawling si visitano pagine e si collezionano altri link da visitare\n",
    "    * quale condizione di terminazione se l'insieme delle pagine non è predeterminato?\n",
    "    * inserire nuovi link in una coda e stabilire una condizione di fermata\n",
    "* usare **parallelismo/concorrenza**\n",
    "    * strutturare l'applicazione in modo  che possa attivare più istanze di **crawler** in parallelo, che seguono percorsi diversi.\n",
    "* tenere sempre presenti gli **aspetti legali!!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb45a5f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## DataSet: a \"data  base for lazy people\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d2600e",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* **https://dataset.readthedocs.io/en/latest/index.html#**\n",
    "* può essere installata con **pip install**\n",
    "* può usare come backend diversi database relazionali\n",
    "    * **MySQL**\n",
    "    * **Postgres**\n",
    "    * **SQLite**\n",
    "* useremo come back end **SQLite**\n",
    "    * lightweigth, serverless, self-contained data-base\n",
    "    * integrato in Python: non occorrono installazioni aggiuntive\n",
    "    * adatto per progetti di piccole dimensioni\n",
    "* **DataSet** fornisce una semplice interfaccia verso **SQLite**, con alcune limitrazioni\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00441076",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## DataSet: a data  base for lazy people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb29416b",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dataset\n",
    "db = dataset.connect('sqlite:///mydatabase.db')\n",
    "table = db['simpletable']\n",
    "\n",
    "# Inserzione di un nuovo record\n",
    "table.insert(dict(name='Mario Rossi', age=46, country='Italy'))\n",
    "\n",
    "# dataset will create \"missing\" columns any time you insert a dict with an unknown key\n",
    "table.insert(dict(name='Bob White', age=37, country='USA', gender='male'))\n",
    "\n",
    "table.update(dict(name='Bob White', age=47), ['name'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861b00f9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## DataSet: a data  base for lazy people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4d8eb6d",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['simpletable']\n"
     ]
    }
   ],
   "source": [
    "print(db.tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7aeb1cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'name', 'age', 'country', 'gender']\n"
     ]
    }
   ],
   "source": [
    "print(table.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5d5aa4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'name', 'age', 'country', 'gender']\n"
     ]
    }
   ],
   "source": [
    "print(db['simpletable'].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "daa7e77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "47\n",
      "46\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "for user in db['simpletable']:\n",
    "    print(user['age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c015b98f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## DataSet: a data  base for lazy people: queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "752f0109",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Italy 2\n",
      "USA 2\n"
     ]
    }
   ],
   "source": [
    "result = db.query('SELECT country, COUNT(*) c FROM  SIMPLETABLE GROUP BY country')\n",
    "for row in result:\n",
    "    print(row['country'], row['c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e98f53",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Crawling in parallel: la libreria JobLib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073b6e1d",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* Python offre diverse opzioni per la programmazione parallela\n",
    "\n",
    "* adatta soprattutto per **embarassengly parallel computations**\n",
    "    * un programma che richiede di effettuare diverse computaizoni\n",
    "    * ogni computazione è indipendente dalle altre\n",
    "    * ad esempio: calcolare la redice qudrata di tutti inumeri contenuti in una lista\n",
    "    * possibilità domeseguire le computazioni in parallelo, su core diversi\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8380e3cf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Crawling in parallel: la libreria JobLib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f0f78",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<code>\n",
    "def square(x):\n",
    "    time.sleep(1)  # Simulating a time-consuming task\n",
    "    return x ** 2\n",
    "\n",
    "delayed_calls = [delayed(square)(number) for number in numbers]\n",
    "results_delayed = Parallel(n_jobs=-1)(delayed_calls)\n",
    "</code>\n",
    "\n",
    "* mettendo -1 nel `n_jobs` indico che voglio occuprare tutti i core che posso -1 , che e' quello gia' occupato dal processo chiamante"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a4c990",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Joblib: embarassingly parallelism in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2035bb8",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results without delayed: [1, 4, 9, 16, 25]\n",
      "Results with delayed:    [1, 4, 9, 16, 25]\n",
      "Time without delayed:    5.0148231983184814\n",
      "Time with delayed:       1.0664722919464111\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import time\n",
    " \n",
    "def square(x):\n",
    "    time.sleep(1)  # Simulating a time-consuming task\n",
    "    return x ** 2\n",
    " \n",
    "# List of numbers\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    " \n",
    "# Without using delayed\n",
    "start = time.time()\n",
    "results_no_delayed =[square(number) for number in numbers]\n",
    "end = time.time()\n",
    "time_no_delayed = end - start\n",
    " \n",
    "# Using delayed\n",
    "start = time.time()\n",
    "delayed_calls = [delayed(square)(number) for number in numbers]\n",
    "results_delayed = Parallel(n_jobs=-1)(delayed_calls)\n",
    "end = time.time()\n",
    "time_delayed = end - start\n",
    " \n",
    "print(\"Results without delayed:\", results_no_delayed)\n",
    "print(\"Results with delayed:   \", results_delayed)\n",
    "print(\"Time without delayed:   \", time_no_delayed)\n",
    "print(\"Time with delayed:      \", time_delayed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249011dd-1114-4ca2-af1d-6fe12cba0829",
   "metadata": {},
   "source": [
    "#### -> Un metodo per ottimizzare e ridurre il tempo di lavoro, soprattutto se lavoro con pandas, e' la scelta di un tipo di variabile compatibile con lo scopo e la precisione richiesta dal lavoro che devo svolgere"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6451725",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Crawling and analysing Wikiperdia graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd662b4",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* scopo dell'esercizio\n",
    "    * individuare, mediante scraping i titoli delle pagine di wikipedia\n",
    "    * individuare i link esistenti tra le pagine\n",
    "    * costruire un grafo che rappresenti la relazione tra le pagine\n",
    "    * analizzare il grafo\n",
    "* cosa utilizzeremo\n",
    "    * **BeutifulSoup**\n",
    "    * la libreria **dataset** per creare un semplice database per memorizzare le informazioni reperite\n",
    "    * **NetworkX** per analizzare e visualizzare il grafo risultante\n",
    "    * la libreria **parallel**\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0f2ee8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Crawling and analysing Wikiperdia graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bc5ab6",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"Figures/Wikipedia.jpg\" style=\"width:800px;height:800px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e76a93",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Crawling and analysing Wikiperdia graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06136ba9",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* non vogliamo considerare link che puntano a siti esterni a Wikipedia\n",
    "* ad esempio, nella figura sotto, i link che puntano a progetti \"gemelli\", come **wikisource**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613ea9fe",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"Figures/LinkEsterni.jpg\" style=\"width:1000px;height:400px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb0b116",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Crawling and analysing Wikiperdia graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44181524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import dataset\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urldefrag\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "db = dataset.connect('sqlite:///wikipedia.db')\n",
    "table_links = db['links']\n",
    "table_pages = db['pages']\n",
    "base_url = 'https://en.wikipedia.org/wiki/'\n",
    "\n",
    "def store_page(url, title):\n",
    "    print('Visited page:', url)\n",
    "    print(' title:', title)\n",
    "    table_pages.upsert({'url': url, 'title': title}, ['url']) \n",
    "    \n",
    "def store_links(from_url, links):\n",
    "    db.begin()\n",
    "    for to_url in links:\n",
    "        table_links.upsert({'from_url': from_url, 'to_url': to_url}, ['from_url', 'to_url'])\n",
    "    db.commit()\n",
    "    print(\"**link stored**\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3ac42f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Crawling and analysing Wikiperdia graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef72ece6",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_random_unvisited_pages(amount=10):\n",
    "    result = db.query('''SELECT * FROM LINKS\n",
    "        WHERE to_url NOT IN (SELECT url FROM PAGES)\n",
    "        ORDER BY RANDOM() LIMIT {}'''.format(amount))\n",
    "    print( result)\n",
    "    return [r['to_url'] for r in result]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46b1139",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* query **SQL-like** sul database\n",
    "* si seleziona un link che porta ad una pagina che non è stata ancora visitata\n",
    "    * si selezionano i links presenti nella tabella **LINKS**\n",
    "    * si analizza il campo **to_url**, che indica la pagina a cui punta quel link\n",
    "    * quella pagina non deve essere nelle **url** contenute nella tabella **PAGES**, che contiene le pagine già visitate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97f9068",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Crawling and analysing Wikiperdia graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34a69ae",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def should_visit(base_url, url):\n",
    "    if url is None:\n",
    "        return None\n",
    "    if not url.startswith(base_url):\n",
    "        # questa è una URL esterna, non punta a una pagina interna di Wikiperia\n",
    "        return None\n",
    "    full_url = urljoin(base_url, url)\n",
    "    full_url = urldefrag(full_url)[0]    \n",
    "    ignore = ['Wikipedia:', 'Template:', 'File:', 'Talk:', 'Special:',\n",
    "                'Template talk:', 'Portal:', 'Help:', 'Category:', 'index.php']\n",
    "    if any([i in full_url for i in ignore]):\n",
    "        # Pagina da ignorare\n",
    "        return None\n",
    "    return full_url\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f21a98",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Crawling and analysing Wikiperdia graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78685123",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    " def get_title_and_links(base_url, url):\n",
    "    html = requests.get(url).text\n",
    "    html_soup = BeautifulSoup(html, 'html.parser')\n",
    "    page_title = html_soup.find(class_='mw-page-title-main')\n",
    "    page_title = page_title.text if page_title else ''\n",
    "    links = []\n",
    "    for link in html_soup.find_all(\"a\"):\n",
    "        link_url = should_visit(base_url, link.get('href'))\n",
    "        if link_url:\n",
    "            links.append(link_url)\n",
    "    return url, page_title, links\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baed542d",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* **Parallel**: classe offerta dal package **Joblib** \n",
    "* il parametro **n_jobs** indica quanti processi eseguire in parallelo\n",
    "    * valore **-1** indica che si vogliono usare tutti i job disponibili\n",
    "* **delayed** è un **decorator** che permette alla classe **Parallel** di interagire con la funzione da eseguire\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c554d193",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Crawling and analysing Wikiperdia graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7857435",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    urls_to_visit = [base_url]\n",
    "    print(urls_to_visit)\n",
    "    while urls_to_visit:\n",
    "        scraped_results = Parallel(n_jobs=5, backend=\"threading\")(\n",
    "            delayed(get_title_and_links)(base_url, url) for url in urls_to_visit\n",
    "        )\n",
    "        print(\"I am here\")\n",
    "        for url, page_title, links in scraped_results:\n",
    "            store_page(url, page_title)\n",
    "            store_links(url, links)\n",
    "        urls_to_visit = get_random_unvisited_pages()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b29e615",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* prima soluzione per terminare il crawling: **interrompere il kernel nel Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706b8962",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Crawling and analysing Wikiperdia graph: analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3dd41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx \n",
    "import matplotlib.pyplot as plt\n",
    "import dataset\n",
    "db = dataset.connect('sqlite:///wikipedia.db')\n",
    "G = networkx.DiGraph()\n",
    "print('Building graph...')\n",
    "for page in db['pages'].all():\n",
    "    G.add_node(page['url'], title=page['title'])\n",
    "for link in db['links'].all():\n",
    "    # Only addedge if the endpoints have both been visited\n",
    "    if G.has_node(link['from_url']) and G.has_node(link['to_url']):\n",
    "        G.add_edge(link['from_url'], link['to_url'])\n",
    "# Unclutter by removing unconnected nodes\n",
    "G.remove_nodes_from(networkx.isolates(G))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7fabf5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Crawling and analysing Wikiperdia graph: analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec9835b",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate node betweenness centrality as a measure of importance\n",
    "print('Calculating betweenness...')\n",
    "betweenness = networkx.betweenness_centrality(G, endpoints=False)\n",
    "print(betweenness)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3f5de5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Crawling and analysing Wikiperdia graph: plotting the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961fc74b",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print('Drawing graph...')\n",
    "# Sigmoid function to make the colors (a little) more appealing\n",
    "squash = lambda x : 1 / (1 + 0.5**(20*(x-0.1)))\n",
    "colors = [(0, 0, squash(betweenness[n])) for n in G.nodes()]\n",
    "labels = dict((n, d['title']) for n, d in G.nodes(data=True))\n",
    "positions = networkx.spring_layout(G)\n",
    "networkx.draw(G, positions, node_color=colors, edge_color='#AEAEAE')\n",
    "# Draw the labels manually to make them appear above the nodes\n",
    "for k, v in positions.items():\n",
    "    plt.text(v[0], v[1]+0.025, s=labels[k],\n",
    "        horizontalalignment='center', size=8)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1a2770",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plotting graph con Gephi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbf8d5d",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* un tool open-source molto popolare per la visualizzazione di grafi e reti che presenta funzionalità più avanzate rispetto \n",
    "a **NetworkX**\n",
    "* **Layout**\n",
    "    * **ForceAtlas**: riduce la distanza tra nodi con molte connessioni e la aumenta tra quelli con poche connessioni\n",
    "* **Colori**\n",
    "    * possono essere associati a diverse caratteristiche dei nodi\n",
    "    * possono indicare il rank del nodo/dell'arco rispetto a qualche statistica\n",
    "* **Filtri**\n",
    "    * possibilità di effettuare uno **zoom** su parti deverse del grafo\n",
    "    * giant component\n",
    "    * ego network\n",
    "    * comunità di nodi\n",
    "    * attributi particolari\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147c1c71",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "networkx.write_gexf(G, \"Wikipedia.gexf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed32a62",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* possibile esportare un grafo da **NetworkX** nel formato **GEXF (Graph Exchange XML Format)**\n",
    "* è un formato interpretato da **Gephi**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9ad867",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Astrazione delle transazioni di Bitcoin: il DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0155ff37",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"Figures/BitcoinTransactionChain.jpg\" style=\"width:800px;height:400px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb56152",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Astrazione delle transazioni di Bitcoin: il DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31938903",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"Figures/BitcoinTables.jpg\" style=\"width:700px;height:600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185f3902",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Astrazioni effettuate nel dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179c34b2",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "I principali elementi di una transazione **Bitcoin** sono i seguenti\n",
    "<ul>\n",
    "<li><b>hash</b>: identificatore della transazione </li>\n",
    "<li><b>block_id</b>: identificatore del blocco che contiene la transazione </li>\n",
    "<li><b>version</b></li>\n",
    "<li><b>size</b></li>\n",
    "<li><b>lock_time</b>: tempo prima del quale una transazione non può essere inserita in un blocco</li>\n",
    "<li><b>vin_sz</b></li>\n",
    "<li><b>vout_sz</b></li>\n",
    "<li><b>inputs</b></li>\n",
    "<li><b>outputs</b></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9a0c82",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Astrazioni effettuate nel dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51de1da",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "I campi eliminati nel nostro dataset sono i seguenti:\n",
    "<ul>\n",
    "<li><b>version</b></li>\n",
    "<li><b>size</b></li>\n",
    "<li><b>lock_time</b></li>\n",
    "<li><b>vin_sz</b></li>\n",
    "<li><b>vout_sz</b></li>\n",
    "</ul>\n",
    "\n",
    "* nel dataset, tutti i campi   <b>hash</b> sono stati sostituiti con un identificatore numerico <b>id</b>\n",
    "\n",
    "* questo ha permesso di ridurre la dimensione del dataset\n",
    "\n",
    "* inoltre le chievi pubbliche e le corrispondenti firme sono astatte da identificatori"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b26702",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Analisi richieste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0deeb53",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* controllare se esistono blocchi o transazioni invalide nel dataset ed eventualmente rimuoverli/e\n",
    "* calcolare le seguenti statistiche\n",
    "    * distribuzione dei blocchi: numero di transazioni per ogni blocco, considerando l'intero periodo di tempo e per mese\n",
    "    * distribuzione delle fee spese in ogni transazione nell'intero periodo\n",
    "    * quanti UXTO esistono, al momento del mining dell'ultimo blocco del data set?\n",
    "    * quale è l'UXTO a cui è associato il valore più alto?\n",
    "    * trovare tutte le transazioni generate tra due date\n",
    "* proporre almeno una analisi non compresa tra le precedenti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53dbbc3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Analisi di Bitcoin: il DataFrame delle transazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5a3c4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tx_id  blk_id\n",
      "0      1       0\n",
      "1      2       1\n",
      "2      3       2\n",
      "3      4       3\n",
      "4      5       4\n",
      "         tx_id  blk_id\n",
      "216621  216622  100016\n",
      "216622  216623  100016\n",
      "216623  216624  100016\n",
      "216624  216625  100016\n",
      "216625  216626  100017\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as mat\n",
    "import numpy as np\n",
    "\n",
    "#costruzione dei DataFrames\n",
    "\n",
    "Transactions = pd.read_csv('Dataset/Transactions.csv',names=['tx_id', 'blk_id'])\n",
    "Inputs = pd.read_csv('DataSet/Inputs.csv', names=['in_id', 'tx_id', 'sig_id', 'output_id'])\n",
    "Outputs = pd.read_csv('DataSet/Outputs.csv', names=['output_id', 'tx_id', 'pk_id', 'value'])\n",
    "\n",
    "print(Transactions.head())\n",
    "print(Transactions.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e63b38",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* primo passo: osservazione del **DataSet**\n",
    "\n",
    "* una sola transazione per blocco, nei primi blocchi del **DataSet**\n",
    "   * si tratta di **Coinbase**\n",
    "   * transazioni di ricompensa al miner che ha risolto la **Proof of Work**\n",
    "   * probabilmente minate da **Nakamoto** stesso\n",
    "* gli ultimi blocchi includono più transazioni\n",
    "* numero ultima transazione >> numero dell'ultimo blocco\n",
    "   * diverse blocchi contengono molte transazioni\n",
    "   \n",
    "* **nota bene**: lo stesso nome **output_id** come identificatore di un output e come riferimento in un campo input.\n",
    "    * questo ci consentirà di effettuare il **merge** dei due dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db11f174",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Analisi  di Bitcoin: il DataFrame degli Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20c65167",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   in_id  tx_id  sig_id  output_id\n",
      "0      1      1       0         -1\n",
      "1      2      2       0         -1\n",
      "2      3      3       0         -1\n",
      "3      4      4       0         -1\n",
      "4      5      5       0         -1\n",
      "         in_id   tx_id  sig_id  output_id\n",
      "292422  292423  216622   95854     258874\n",
      "292423  292424  216623  161394     247315\n",
      "292424  292425  216624  173913     263227\n",
      "292425  292426  216625  174188     263611\n",
      "292426  292427  216626       0         -1\n"
     ]
    }
   ],
   "source": [
    "print(Inputs.head())\n",
    "print(Inputs.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8692c9be",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* primo passo: osservazione del **DataSet**\n",
    "* nelle prime righe l'**output_id** è sempre uguale  a **-1**\n",
    "    * questo conferma che si tratta di transazioni **Coinbase**: non c'è un puntatore a una transazione precedente\n",
    "    * i bitcoin sono stati creati dal sistema, non provengono da una transazione precedente\n",
    "    * gli **in_id** corrispondono ai **tx_id**\n",
    "        * un solo input dummy per ogni transazione, non significativo (non punta a un output precedente)\n",
    "* nelle ultime righe: il numero di **in_id** > **tx_id**\n",
    "    * esisteno transazioni con più di un input, molte transazioni con un solo input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdf3beb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Analisi di Bitcoin: il DataFrame degli Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0e4b7de",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   output_id  tx_id  pk_id       value\n",
      "0          1      1      1  5000000000\n",
      "1          2      2      2  5000000000\n",
      "2          3      3      3  5000000000\n",
      "3          4      4      4  5000000000\n",
      "4          5      5      5  5000000000\n",
      "        output_id   tx_id   pk_id       value\n",
      "264305     264306  216623  174700     1000000\n",
      "264306     264307  216623  174701   299000000\n",
      "264307     264308  216624  167815     1000000\n",
      "264308     264309  216625  174695     1200000\n",
      "264309     264310  216626  174701  5000000000\n"
     ]
    }
   ],
   "source": [
    "print(Outputs.head())\n",
    "print(Outputs.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962e6ec2",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* primo passo: osservazione del **DataSet**\n",
    "\n",
    "* le prime transazioni contengono un solo output\n",
    "  * l'output corrisponde alla ricompensa data ai miners\n",
    "  * inizialmente era di 5000000000 Satoshi = 50 BTC, poi dimezzata ogni 4 anni\n",
    "* nelle ultime righe il numero di **output_id** > **tx_id**\n",
    "  * esistono transazioni con output multipli\n",
    "  * ad esempio la transazione <code> 216623 </code>  ha due output diversi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65357250",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Controlli di validità delle transazioni: quali?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0e025f",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* Input/output che fanno riferimento ad un tx_id non contenuto in nessun blocco\n",
    "* Input che fanno riferimento ad un output_id non esistente\n",
    "* Transazioni con pk_id/sign_id negativi\n",
    "* Output con campo “amount” negativo\n",
    "* Transazioni in double spending\n",
    "* Reward per il miner minore di 50 BTC\n",
    "* Si cercano di spendere dei bitcoin appartenenti ad un indirizzo diverso dal proprio \n",
    "    * la chiave pubblica non è consistente con la firma\n",
    "    * nel nostro caso, l'identificatore nell'output non corrisponde con quello nell'input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ee8995",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Controlli di validità delle transazioni: corrispondenza chiave pubblica-firma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20620f22",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* le chiavi pubbliche e le firme sono astratte nel datset con degli identificatori\n",
    "* la corrispondenza tra chiave pubblica e signature è verificata in **Bitcoin** da uno script **FORTH** \n",
    "* nel nostro caso occorre verificare solamente la corrispondenza tra gli identificatori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6446a416",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ricerca corrispondenza errate tra pk_id e sig_id\n",
      "\n",
      "   output_id  tx_id_x  pk_id       value   in_id  tx_id_y  sig_id\n",
      "0         10       10     10  5000000000     172      172      10\n",
      "1        172      172    172  1000000000  219200   156787     172\n",
      "2        173      172     10  4000000000     184      184      10\n",
      "3        186      184     10  3000000000     186      186      10\n",
      "4        188      186    186   100000000     228      228     186\n",
      "\n",
      "Transazioni inconsistenti trovate = 2\n",
      "\n",
      "       output_id  tx_id_x   pk_id       value   in_id  tx_id_y  sig_id\n",
      "1678       16121    16081   16020  5000000000  194075   138278  139250\n",
      "83064     137338   116208  113300  5000000000  157972   116411      -1\n"
     ]
    }
   ],
   "source": [
    "#ricerca di record collegati tra input e output che non hanno i campi sig_id e pk_id uguali\n",
    "    \n",
    "print(\"ricerca corrispondenza errate tra pk_id e sig_id\")\n",
    "print()\n",
    "\n",
    "InputOutput = pd.merge(Outputs, Inputs, on=\"output_id\")\n",
    "print(InputOutput.head())\n",
    "print()\n",
    "\n",
    "Invalid_pk_sig = InputOutput.loc[InputOutput ['sig_id'] != InputOutput ['pk_id']]\n",
    "\n",
    "print(\"Transazioni inconsistenti trovate =\", len(Invalid_pk_sig.index))\n",
    "print()\n",
    "print(Invalid_pk_sig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9e53a5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Controlli di validità delle transazioni: corrispondenza chiave pubblica-firma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0f0765",
   "metadata": {},
   "source": [
    "* **merge**: una **join** su cui si può specificare la colonna su cui fondere i dataframe\n",
    "    * per default calcola un **inner join**\n",
    "    * calcola l'intersezione dei due **DataFrame**\n",
    "  \n",
    "* per individuare le transazioni invalide, si sfrutta uno dei tanti modi di utilizzare la funzione **Python loc**\n",
    "\n",
    "    * si crea un   **row indexer**, un Serie di valori **Booleani**\n",
    "    ```python \n",
    "    InputOutput.loc[InputOutput ['sig_id'] != InputOutput ['pk_id']]\n",
    "    ```\n",
    "    * la Serie è creata confrontando valori corrispondenti delle due serie, corrispondenti a due colonne del **DataFrame**\n",
    "    ```python \n",
    "    InputOutput ['sig_id'] \n",
    "    InputOutput ['pk_id']\n",
    "    ```\n",
    "    \n",
    "* si passa il **row indexer** di valori booleani alla funzione **loc**\n",
    "* la **Series** di valori booleani deve essere **allineata** con le righe del **DataFrame**    \n",
    "* solo le righe in cui il valore corrispondente in **row indexer** è **True**, vengono selezionate \n",
    "* viene costruito un nuovo **DataFrame** con le righe selezionate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f31747",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Calcolo valore totale UTXO: individuazione output non spesi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454a38d4",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* quale è il valore degli UXTO, al momento del mining dell'ultimo blocco del data set?\n",
    "* **UTXO** valori non ancora spesi, stanno nell'output di una transazione, ma non sono riferiti dall'input di nessuna altra transazione\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f545519",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calcolo valore totale in UXTO\n",
      "<class 'pandas.core.series.Series'>\n",
      "count     264310\n",
      "unique         2\n",
      "top        False\n",
      "freq      192404\n",
      "Name: output_id, dtype: object\n",
      "0    True\n",
      "1    True\n",
      "2    True\n",
      "3    True\n",
      "4    True\n",
      "Name: output_id, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(\"Calcolo valore totale in UXTO\")\n",
    "\n",
    "# ricerca gli Output non spesi\n",
    "# ovvero gli Output che non hanno una corrispondenza in Inputs\n",
    "# essi rappresentano gli UTXO (Unspent Transaction Outputs)\n",
    "\n",
    "temp = (~Outputs['output_id'].isin(Inputs['output_id']))\n",
    "print(type(temp))\n",
    "print(temp.describe())\n",
    "print(temp.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f9031c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* si utilizza la funzione:\n",
    "   ```python \n",
    "    S.isin(V)\n",
    "    ```\n",
    "\n",
    "* controlla se gli elementi della series **S**  sono contenuti nella serie  **V**\n",
    "* restituisce una **Series di valori booleani** che indica\n",
    "    * per ogni elemento della serie **S**, se quell'elemento è contenuto nella sequenza  **V**\n",
    "    * tale serie di valori booleani verrà poi passata alla funzione **loc**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ce4291",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Calcolo valore totale UTXO: individuazione output non spesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "493ad0c1",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALCOLO TOTALE UTXO\n",
      "        output_id   tx_id   pk_id       value\n",
      "0               1       1       1  5000000000\n",
      "1               2       2       2  5000000000\n",
      "2               3       3       3  5000000000\n",
      "3               4       4       4  5000000000\n",
      "4               5       5       5  5000000000\n",
      "...           ...     ...     ...         ...\n",
      "264305     264306  216623  174700     1000000\n",
      "264306     264307  216623  174701   299000000\n",
      "264307     264308  216624  167815     1000000\n",
      "264308     264309  216625  174695     1200000\n",
      "264309     264310  216626  174701  5000000000\n",
      "\n",
      "[71906 rows x 4 columns]\n",
      "0         5000000000\n",
      "1         5000000000\n",
      "2         5000000000\n",
      "3         5000000000\n",
      "4         5000000000\n",
      "             ...    \n",
      "264305       1000000\n",
      "264306     299000000\n",
      "264307       1000000\n",
      "264308       1200000\n",
      "264309    5000000000\n",
      "Name: value, Length: 71906, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"CALCOLO TOTALE UTXO\")\n",
    "\n",
    "# ricerca gli Output non spesi\n",
    "# ovvero gli Output che non hanno una corrispondenza in Inputs\n",
    "# essi rappresentano gli UTXO (Unspent Transaction Outputs)\n",
    "\n",
    "\n",
    "UTXO = Outputs.loc[temp]\n",
    "print(UTXO)\n",
    "print(UTXO.value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a658e667",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Calcolo dell'UTXO massimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "333ca3af",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Massimo UTXO = 9000000000000\n",
      "Somma totale UTXO = 500140414333354\n",
      "   output_id   tx_id   pk_id          value  blk_id\n",
      "0     170430  140479  138895  9000000000000   90532\n"
     ]
    }
   ],
   "source": [
    "#ricerca del valore massimo\n",
    "\n",
    "MaxUTXO = UTXO.value.max()\n",
    "print(\"Massimo UTXO =\", MaxUTXO )\n",
    "SumUTXO = UTXO.value.sum()\n",
    "print(\"Somma totale UTXO =\", SumUTXO )\n",
    "#cerco la somma di tutti i valori\n",
    "\n",
    "\n",
    "MaxUTXO_tx = UTXO.loc[UTXO['value'] == MaxUTXO] #cerco la riga  con valore massimo\n",
    "MaxUTXO_tx = pd.merge(MaxUTXO_tx, Transactions, on=['tx_id'])\n",
    "print(MaxUTXO_tx)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6f79b6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Analisi delle transazioni: calcolo delle fee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5a5ccd",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* calcolare la distribuzione delle fee spese in ogni transazione nell'intero periodo contenuto nel **DataSet**\n",
    "    * considerare tutte le transzioni, a parte le **CoinBase**\n",
    "* calcolo delle fees per ogni transazione\n",
    "   <center>\n",
    "    $ \\sum (input) - \\sum (output)$\n",
    "    </center>\n",
    "    \n",
    "  dove **input** e **output** sono i valori in input e output della transazione\n",
    "* calcoliamo la somma dei **valori in input** e quella dei **valori in output** separatamente\n",
    "    * somma dei valori in output di una transazione\n",
    "        * <code> group_by </code> su <code> Output </code> in base a <code> tx_id </code>\n",
    "    * somma dei valori in input di una transazione\n",
    "        * i valori in input di una transazione sono contenuti nel precedente **UTXO**\n",
    "        * occorre fare un merge tra <code> Input </code> e <code> Output </code> su <code> output_id </code> \n",
    "        * attenzione a non confondere i <code> tx_id </code> in  <code> Output </code> e quello in <code> Input </code> quando si fa la merge!\n",
    "            * per il calcolo delle fee, interessa <code> tx_id </code>  di  <code> Input </code>!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41deb88",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Analisi delle transazioni: calcolo valore in output di ogni transazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d1cc24",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# elimino la colonna relativa allo script di firma, inutile\n",
    "\n",
    "Out=Outputs.drop(['pk_id'], axis=\"columns\")\n",
    "\n",
    "# raggruppo gli output per transazione \n",
    "# ogni gruppo comprende gli output di una transazione\n",
    "# aggrego, sommando per calcolare la somma degli output uscenti di ogni transazione\n",
    "\n",
    "OutTrans = Out.groupby('tx_id')['value'].sum().reset_index()  \n",
    "OutTrans\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2518e4c",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* il campo **pk_id** non è utile per questa analisi, riguarda lo script per la verifica della firma\n",
    "    * eliminiamo la colonna corrispondente dal **DataSet**\n",
    "* **drop** rimuove una colonna o una riga specifica\n",
    "    * **axis** specifica se si vuole eliminare una colonna o una riga\n",
    "        * **axis=\"columns\"** - colonna\n",
    "        * **axis=\"index\"** - riga\n",
    "    * la colonna viene eliminata nel nuovo dataset creato, non in quello originale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddcf3b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Analisi delle transazioni: calcolo valore in input di ogni transazione"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f065e0eb",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* il problema della determinazione dei valori in input è più complesso, perchè\n",
    "    * il valore di un input di una transazione si trova in un **Unspent Transaction Output (UTXO)** di una transazione precedente\n",
    "    * <code> group_by </code> non è sufficiente,  ora serve collegare due diverse transazioni, quella che genera l'**UTXO**, e quella che lo spende\n",
    "        * si utilizza una <code> merge </code>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbc8fff",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Inp = Inputs.drop(['sig_id'] , axis=1)\n",
    "Out = Outputs.drop(['tx_id', 'pk_id'], axis=1)\n",
    "InpValues = pd.merge(Inp, Out, on='output_id')\n",
    "InpValues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5899f76a",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* drop: elimina i campi non importanti per questa analisi\n",
    "    * nota bene: si elimina **tx_id** dal DataSet degli **Output**, perchè non interessa l'indice della transazione che produce l'**UTXO**, ma di quella che consuma gli output della transazione precednete\n",
    "* merge\n",
    "    * come una **inner join** sui due **DataFrame**\n",
    "    * combina le righe con valore comune dell'attributo **output_id**\n",
    "    * ogni input viene collegato all'output di una transazione precedente, di cui spende il valore\n",
    "* analizziamo la riga <code> 192403 </code>\n",
    "```\n",
    "292419 216618 264284 13836000000\n",
    "```\n",
    "\n",
    "    * la transazione <code> 216618 </code>ha un input di indice <code> 292419</code>  che \"consuma un output precedente\" di indice <code> 264284</code>  di valore <code> 13836000000</code> . \n",
    "    * non interessa l'indice della transazione precedente, solo il valore in output che viene speso nell'input della transazione <code> 216618</code> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33615854",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Analisi delle transazioni: Coinbase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ab6f14",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* la procedura precedente non considera le **Coinbase**\n",
    "* cosa è una **Coinbase**?\n",
    "    * la prima transazione in ogni blocco della blockchain\n",
    "    * utilizzata per inviare la ricompensa al miner che ha minato quel blocco\n",
    "* il formato è lo stesso delle altre transazioni eccetto che\n",
    "    * ha esattamente un input\n",
    "    * quell'input non punta ad un **UXTO** precedente e non contiene un dato significativo\n",
    "    * può contenere messaggia arbitrari\n",
    "        * il messaggio di **Nakamoto** nella prima Coinbase: *“The Times 03/Jan/2009 Chancellor on brink of second bailout for banks\"*\n",
    "    * non ha fee, perchè le transazioni sono inserite nel blocco dal moner stesso\n",
    "* gli output della transazione\n",
    "    * possono essere in numero arbitrario\n",
    "    * uno o più indirizzi del miner\n",
    "    * la somma dei valori in output non può superare la somma della ricompensa data al miner con le fee di tutte le transazioni di quel blocco.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b3e3b1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Analisi delle transazioni: Coinbase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d74570",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Nel nostro DataSet\n",
    "    * le **Coinbase** sono  transazioni che contengono un solo input\n",
    "    * quell'input ha valore **-1**\n",
    "    * il <code> sig_id </code> vale **0**\n",
    "* le coinbase non sono incluse nel risultato del <code> merge </code>, perchè non c'è corrispondenza con un precedente <code> output_id </code>\n",
    "* verifichiamolo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba73c26",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(InpValues.loc[InpValues[\"output_id\"]==-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72644aeb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Analisi delle transazioni: calcolo valore in input di ogni transazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ae89b7",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "InpValues.rename(columns={'in_id':'in_id', 'tx_id':'tx_id' , 'output_id':'utxo_id' , 'value':'value_to_be_spent'}, inplace=True)\n",
    "InpTrans = InpValues.groupby('tx_id')['value_to_be_spent'].sum().reset_index()\n",
    "InpTrans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74033548",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Analisi delle transazioni: calcolo delle fee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a578005",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#raggruppo per indice della transazione \n",
    "#unisco i Dataframe per avere, per ogni transazione, il valore speso e il valore uscente\n",
    "\n",
    "Tx = pd.merge(InpTrans, OutTrans, on='tx_id') \n",
    "\n",
    "#aggiungo la colonna delle fees\n",
    "\n",
    "Tx['fees'] = Tx['value_to_be_spent'] - Tx['value'] \n",
    "\n",
    "TxGreter0 = Tx.loc[Tx['fees'] > 0].sort_values('fees')\n",
    "TxLessEq0 = Tx.loc[Tx['fees'] == 0]\n",
    "TxLessLess0 = Tx.loc[Tx['fees'] < 0].sort_values('fees')\n",
    "\n",
    "TxGreter0 , TxLessEq0, TxLessLess0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1f7ae0",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "* esiste una transazione con fee negativa: un errore nel Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55da90bb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Analisi delle transazioni: calcolo delle fee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf63fed",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#plotting della distribuzione delle fees con valore maggiore di 0\n",
    "Tx_Correct=Tx.loc[Tx['fees']>=0]\n",
    "print(Tx_Correct)\n",
    "X = list(Tx_Correct['tx_id'])\n",
    "mat.plot(X,Tx_Correct['fees'])\n",
    "mat.xlabel('Id transazioni che includono le fees', fontsize=13)\n",
    "mat.ylabel('Valore fees', fontsize=13)\n",
    "mat.yscale('log')\n",
    "mat.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56990d42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
